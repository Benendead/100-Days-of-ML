Day 1: July 5th, 2018
Today's Progress: I've moved from 75% to 85% done with Codecademy's introductory Python course. I finished up sections on
list/dictionary manipulation and also bitwise operations. I'm now a bit over halfway through the Classes section, which is a
welcome step up in complexity. I should be able to finish this course within the week, maybe tomorrow if I work at it.
Thoughts: I'm finally in the Classes segment of a coding course, so you know I'm getting up there. One particularly
interesting section of code they had me write was this bitwise operation method:

# This method flips a specified bit in a given number.
def flip_bit(number, n): 
  mask = 0b1 << (n-1) 
  result = mask ^ number 
  return bin(result)
  
Day 2: July 6th, 2018 (1 hour extra so far)
Today's Progress: I finished the Codecademy Python course this morning and then spent the rest of that first hour beginning
a linear algebra book. Tonight, in a second hour of work, I began reading Learning From Data before realizing that a more 
rigorous background in linear algebra is needed, and so I've now began the UTAustinX Linear Algebra - Foundations to 
Frontiers course on edX. My goal is to complete that course, supplifmented by the mentioned workbook, and then see how far I
can comprehend Learning From Data. Added note: I'm on 0.2.4 of the edX course, as it doesn't save my progress on its own.
Thoughts: It's frusturating to constantly need a more robust background in whatever math area is next, but I hope that by 
cracking down and working hard I can truly gain understanding of these fundamentals so that my ML endeavors are a breeze.

Day 3: July 7th, 2018 (1 cumulative hour extra)
Today's Progress: Downloaded and activated MATLAB 2018 using my school's license. Took quite a long time to download, so
really only accomplished that, installing XCode (for C compiling), and moving to 0.3.3 in the edX linear algebra (LA from here
on out) course.
Thoughts: Hopeful that I can get in some actual learning progress tomorrow, as opposed to figuring out licenses and just
downloading applications.

Day 4: July 8th, 2018 (1 cumulative hour extra)
Today's Progress: Set up Mathworks Online for the edX course, finished up through 1.2.2 of the course. So far have taken 
almost a page of notes; I'm now on 1.3.1 for tomorrow.
Thoughts: Glad to start learning some notation. The course seems well presented and is clear about the notation; I've already
learned a few things that I hadn't previously encountered in multivariable calculus.

Day 5: July 9th, 2018 (1 cumulative hour extra)
Today's Progress: Moved from edX 1.3.1 to halfway through 1.4.1. I learned basic vector operations, some proof writing skills,
and the intuition for calculating the cost of these simple operations in terms of flops and memops.
Thoughts: About time that I get to do some math/proofs with this course. The flops/memops part reminds me of Big-O notation,
which we touched on in AP Comp Sci, although I'm sure this will evolve into a more rigorous part of the course eventually.
For the sake of honesty, these hours are getting more difficult as I have busier and busier days and need to push these back
late into the night, but I hope that I can do this earlier in the day in the coming week as to avoid dreading this learning.

Days 6 and 7: July 11th, 2018 (2 cumulative hours extra)
Today's Progress: Yesterday, I watched one of Daniel Shiffman's videos on perceptrons. I then attempted to follow along with
his code in Processing, but my laptop couldn't handle the app for whatever reason. Today, I installed Jupyter Notebooks and
developed a perceptron model as my first Python project. It's near completion and I have a ton of ideas for what experiments
to run using it. I did also do at least an hour extra of work today working on this perceptron project.
Thoughts: Python is definitely the way to go, especially when my laptop only has 4GB of RAM. I'm excited to polish up my 
perceptron model and publish it to Github, although I'm certain that there's a lot I could improve on it.

Day 8: July 12th, 2018 (2 cumulative hours extra)
Today's Progress: I added a test method and visualization to the Perceptron project, created more clear training methods,
given the user the option to separate their data into training and test data, and I've begun varying the example number and
allowed training steps to attempt to check that the model can make errors and isn't cheating in some way. I imagine it'll be
ready to release for proofreading sometime tomorrow.
Thoughts: I'd like to make sure my code is crystal clear before I release it and there're glaring holes in my explanations or
code documentation. I should probably learn proper Python documentation formatting.

Day 9: July 13th, 2018 (2 cumulative hours extra)
Today's Progress: Studied Python documentation best practices and then went through my perceptron project and reformatted
all of the class/method comments to proper form. Want to proofread through one more time before publishing.
Thoughts: I'm feeling pretty good about my project now that it's well documented. It creates a sense of legitimacy in
knowing that my code's a lot closer to professional now. Might want to pursue another Python course to round out my 
knowledge in areas of unknown deficiencies.

Days 10 and 11: July 15th, 2018 (1 cumulative hour extra)
Yesterday's Progress: I was busy, had to work, and was unable to study ML yesterday. Good thing I'm working extra hours 
ahead of time.
Today's Progress: I completed the edX course on linear algebra through 1.4.4.6. Still need to finish up the unit, but I 
did work through two proofs today on my own and I'm continuing to improve on the format.
Thoughts: I can't miss another day; it's much more difficult to jump back into linear algebra because it's a new topic for me.

Day 12: July 16th, 2018 (1 cumulative hour extra)
Today's Progress: I actually accumulated a bunch of resources on music/composition/transcription and machine learning, and
then read through one article described a method for transcribing MIDI piano using a CNN. I learned a few terms, got some
intuition, but of course there's a lot more to look up and explore. 
Thoughts: This type of learning process is so much more fun than the dry linear algebra course, which isn't scheduled
as a real course right now anyways, so I may learn like this for a bit. Definitely seeing a ton more applications of my
interest than I was scrolling through vector proofs.

Day 13: July 17th, 2018 (2 cumulative hours extra)
Today's Progress: Read most of an explanatory article on CNNs. Took my own notes, defining terms along the way, and I think
I'm building a fair intuition into the network as a whole.
Thoughts: I should probably buckle down and commit to a beginning-to-end ML book if I'm going to be studying the hard-hitters
anyways. Might crack open my Deep Learning (Goodfellow) book today, try to move through more of the math in the beginning.
Also: I studied another hour, finishing up the ConvNet article and beginning one on using LSTMs/RNNs to compose music.

Days 14 and 15: July 19th, 2018 (1.5 cumulative hours extra)
Yesterday: Missed a day, as I was ironically up so late the night before that I'd completed that extra hour fully in this day.
Today's Progress: I spent a half hour watching and taking notes on two carykh videos, noting his sources and where I can learn
more about his hyperGAN and CNN shenanigans. He makes concepts lucid but doesn't go much in depth, unfortunately. Tonight I
also spent another hour continuing through Daniel Johnson's RNN/LSTM composition project, which got really dense and hence
took me a while to slog through. I believe I can finish the original article with another hour of study.
Thoughts: I should go back and proofread through my perceptron class and publish it, only because I feel as though I may
forget otherwise. It's competent, surely.

Day 16: July 20th, 2018 (1.5 cumulative hours extra)
Today's Progress: Spent the hour debugging, proofreading, and testing the perceptron project. Then released it on Github.
Thoughts: Given that my one completed project was based on a video by Daniel Shiffman, I think that continuing with his
resources for inspiration/learning might be a wise choice.

Day 17: July 21st, 2018 (1.5 cumulative hours extra)
Today's Progress: Watched through Daniel Shiffman's second video on his perceptron model, where he refactored his code and
also added a visualization of the perceptron's current guess of the line. I implemented these changes into my project as well.
Thoughts: Daniel Shiffman's videos are indeed both educational and motivating, I'll keep going through them and then might
start through Siraj's. Good progress and my project is on Github still check it out.

Days 18 and 19: July 23rd, 2018 (1.5 cumulative hours extra)
Yesterday's Progress: Studied another two Daniel Shiffman videos before reaching linear algebra that deserves more dedication,
although perhaps that's my problem of not progressing until every foundation is completely robust. Then spent 20min (still
part of the hour) taking notes on the Deep Learning book by Goodfellow, still in the math section.
Today's Progress: Studied through most of the first unit of a Microsoft edX course called "Essential Math for Machine 
Learning: Python Edition." It's quite basic so far but finishing all of this would (in my mind) legitimize starting other
courses without worrying about all of the math I'm still missing.
Thoughts: Maybe five more days of this Microsoft course and it'll be done at this rate; of course I expect it to pick up
difficulty but we'll see. I also need some pandas and matplotlib literacy work, as they're currently incomprehensible.

Days 20 and 21: July 25th, 2018 (1.5 cumulative hours extra)
Today and Yesterday's Progress: Yesterday I took a Boston University multivariable calculus final exam in order to practice
for a placement test I'll need to take at UR in a few weeks. I got 45/100 on this, which isn't terrible, corrected the test
between yesterday and today, and am now studying the topics in need of review. For example, I studied line integrals as well
as directional derivatives today.
Thoughts: Yes, multivariable is only tangentially related to ML, but passing this test is probably the single most effective
course of action I can pursue in order to accelerate my ML studies in college and beyond. I do plan to finish the other math
edX course as well, simply because it seems both quick and relatively broad in content and hence learning.
